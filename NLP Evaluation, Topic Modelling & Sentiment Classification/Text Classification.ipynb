{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e9258d-1816-4465-90fb-c4940d7b04e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be03184-65b9-4811-b1d9-19bb9888b027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train/dev data: (18646, 3)\n",
      "sentiment\n",
      "neutral     8789\n",
      "positive    5979\n",
      "negative    3878\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Loaded test data: (4662, 3)\n",
      "sentiment\n",
      "neutral     2197\n",
      "positive    1495\n",
      "negative     970\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_path = \"train.txt\"                \n",
    "test_path  = \"ttds_2025_cw2_test.txt\"   \n",
    "\n",
    "# train/dev data\n",
    "train_df = pd.read_csv(\n",
    "    train_path,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"id\", \"sentiment\", \"tweet\"],\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "\n",
    "# keep only the 3 sentiment labels\n",
    "train_df = train_df[train_df[\"sentiment\"].isin([\"positive\", \"negative\", \"neutral\"])]\n",
    "\n",
    "print(\"Loaded train/dev data:\", train_df.shape)\n",
    "print(train_df[\"sentiment\"].value_counts(), \"\\n\")\n",
    "\n",
    "# labelled test data\n",
    "test_df = pd.read_csv(\n",
    "    test_path,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"id\", \"sentiment\", \"tweet\"],\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "\n",
    "test_df = test_df[test_df[\"sentiment\"].isin([\"positive\", \"negative\", \"neutral\"])]\n",
    "\n",
    "print(\"Loaded test data:\", test_df.shape)\n",
    "print(test_df[\"sentiment\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5aee56a-d61b-4504-b39e-0688a48b7415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split size: 16781\n",
      "Dev split size:   1865 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_split_df, dev_split_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,             # 90% train, 10% dev\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"sentiment\"]\n",
    ")\n",
    "\n",
    "print(\"Train split size:\", len(train_split_df))\n",
    "print(\"Dev split size:  \", len(dev_split_df), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0910bc27-ba53-415f-bc0a-e69dab3df477",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_re = re.compile(f\"[{re.escape(string.punctuation)}]\")\n",
    "\n",
    "def tokenize(text: str):\n",
    "    text = str(text)\n",
    "    text = punct_re.sub(\" \", text)\n",
    "    text = text.lower()\n",
    "    return text.split()\n",
    "\n",
    "# tokenised docs\n",
    "train_tokens = [tokenize(t) for t in train_split_df[\"tweet\"]]\n",
    "dev_tokens   = [tokenize(t) for t in dev_split_df[\"tweet\"]]\n",
    "test_tokens  = [tokenize(t) for t in test_df[\"tweet\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e2ce29-4227-4ffa-8ea0-abe73f32b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 37127\n",
      "Feature matrix shapes:\n",
      "  X_train: (16781, 37128)\n",
      "  X_dev:   (1865, 37128)\n",
      "  X_test:  (4662, 37128) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(docs_tokens):\n",
    "    vocab = set()\n",
    "    for doc in docs_tokens:\n",
    "        vocab.update(doc)\n",
    "    return {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "\n",
    "word2id = build_vocab(train_tokens)\n",
    "vocab_size = len(word2id)\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "\n",
    "def convert_to_bow_matrix(preprocessed_docs, word2id):\n",
    "    n_docs = len(preprocessed_docs)\n",
    "    oov_index = len(word2id)\n",
    "    mat_size = (n_docs, oov_index + 1)\n",
    "\n",
    "    X_dok = scipy.sparse.dok_matrix(mat_size, dtype=np.int32)\n",
    "\n",
    "    for doc_id, doc in enumerate(preprocessed_docs):\n",
    "        for word in doc:\n",
    "            token_id = word2id.get(word, oov_index)\n",
    "            X_dok[doc_id, token_id] += 1\n",
    "\n",
    "    return X_dok.tocsr()\n",
    "\n",
    "X_train = convert_to_bow_matrix(train_tokens, word2id)\n",
    "X_dev   = convert_to_bow_matrix(dev_tokens,   word2id)\n",
    "X_test  = convert_to_bow_matrix(test_tokens,  word2id)\n",
    "\n",
    "print(\"Feature matrix shapes:\")\n",
    "print(\"  X_train:\", X_train.shape)\n",
    "print(\"  X_dev:  \", X_dev.shape)\n",
    "print(\"  X_test: \", X_test.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1828be2-c64c-42e6-bccb-2647eb7b7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment2id = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
    "id2sentiment = {v: k for k, v in sentiment2id.items()}\n",
    "\n",
    "y_train = train_split_df[\"sentiment\"].map(sentiment2id).to_numpy()\n",
    "y_dev   = dev_split_df[\"sentiment\"].map(sentiment2id).to_numpy()\n",
    "y_test  = test_df[\"sentiment\"].map(sentiment2id).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f58f70-f8dc-4c12-925f-a610e4264a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(y_true, y_pred):\n",
    "    labels = [\n",
    "        sentiment2id[\"positive\"],\n",
    "        sentiment2id[\"negative\"],\n",
    "        sentiment2id[\"neutral\"],\n",
    "    ]\n",
    "    p, r, f, _ = precision_recall_fscore_support(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    scores = {\n",
    "        \"p-pos\": p[0], \"r-pos\": r[0], \"f-pos\": f[0],\n",
    "        \"p-neg\": p[1], \"r-neg\": r[1], \"f-neg\": f[1],\n",
    "        \"p-neu\": p[2], \"r-neu\": r[2], \"f-neu\": f[2],\n",
    "        \"p-macro\": p.mean(),\n",
    "        \"r-macro\": r.mean(),\n",
    "        \"f-macro\": f.mean(),\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e92737-c0c5-4771-a2fc-253b61616b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      " BASELINE MODEL: SVC (BOW)     \n",
      "================================\n",
      "Baseline dev macro F1: 0.5603\n",
      "Baseline test macro F1: 0.5583 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"================================\")\n",
    "print(\" BASELINE MODEL: SVC (BOW)     \")\n",
    "print(\"================================\")\n",
    "\n",
    "baseline_clf = SVC(C=1000, kernel=\"linear\")\n",
    "\n",
    "baseline_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_baseline = baseline_clf.predict(X_train)\n",
    "y_dev_pred_baseline   = baseline_clf.predict(X_dev)\n",
    "y_test_pred_baseline  = baseline_clf.predict(X_test)\n",
    "\n",
    "baseline_dev_scores = compute_scores(y_dev, y_dev_pred_baseline)\n",
    "baseline_test_scores = compute_scores(y_test, y_test_pred_baseline)\n",
    "\n",
    "print(\"Baseline dev macro F1:\",\n",
    "      f\"{baseline_dev_scores['f-macro']:.4f}\")\n",
    "print(\"Baseline test macro F1:\",\n",
    "      f\"{baseline_test_scores['f-macro']:.4f}\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716320e4-6afb-4f41-82d4-e296516e58c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- LogisticRegression (BOW) -----\n",
      "Dev macro F1:  0.6147\n",
      "Test macro F1: 0.6094 \n",
      "\n",
      "----- RandomForestClassifier (BOW) -----\n",
      "Dev macro F1:  0.4843\n",
      "Test macro F1: 0.4783 \n",
      "\n",
      "----- MultinomialNB (BOW) -----\n",
      "Dev macro F1:  0.5926\n",
      "Test macro F1: 0.5986 \n",
      "\n",
      "----- LinearSVC (BOW) -----\n",
      "Dev macro F1:  0.5957\n",
      "Test macro F1: 0.5810 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_and_eval_model(name, clf, X_train, y_train, X_dev, y_dev, X_test, y_test,\n",
    "                         use_dense=False):\n",
    "    \n",
    "    if use_dense:\n",
    "        X_train_fit = X_train.toarray()\n",
    "        X_dev_fit   = X_dev.toarray()\n",
    "        X_test_fit  = X_test.toarray()\n",
    "    else:\n",
    "        X_train_fit = X_train\n",
    "        X_dev_fit   = X_dev\n",
    "        X_test_fit  = X_test\n",
    "\n",
    "    print(f\"----- {name} -----\")\n",
    "    clf.fit(X_train_fit, y_train)\n",
    "\n",
    "    y_train_pred = clf.predict(X_train_fit)\n",
    "    y_dev_pred   = clf.predict(X_dev_fit)\n",
    "    y_test_pred  = clf.predict(X_test_fit)\n",
    "\n",
    "    dev_scores = compute_scores(y_dev, y_dev_pred)\n",
    "    test_scores = compute_scores(y_test, y_test_pred)\n",
    "\n",
    "    print(\"Dev macro F1: \", f\"{dev_scores['f-macro']:.4f}\")\n",
    "    print(\"Test macro F1:\", f\"{test_scores['f-macro']:.4f}\", \"\\n\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"clf\": clf,\n",
    "        \"y_train_pred\": y_train_pred,\n",
    "        \"y_dev_pred\": y_dev_pred,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        \"dev_scores\": dev_scores,\n",
    "        \"test_scores\": test_scores,\n",
    "    }\n",
    "\n",
    "improved_candidates = []\n",
    "\n",
    "# 1) Logistic Regression \n",
    "logreg = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
    "improved_candidates.append(\n",
    "    train_and_eval_model(\n",
    "        \"LogisticRegression (BOW)\",\n",
    "        logreg,\n",
    "        X_train, y_train,\n",
    "        X_dev,   y_dev,\n",
    "        X_test,  y_test,\n",
    "        use_dense=False\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2) Random Forest \n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "improved_candidates.append(\n",
    "    train_and_eval_model(\n",
    "        \"RandomForestClassifier (BOW)\",\n",
    "        rf,\n",
    "        X_train, y_train,\n",
    "        X_dev,   y_dev,\n",
    "        X_test,  y_test,\n",
    "        use_dense=True  \n",
    "    )\n",
    ")\n",
    "\n",
    "# 3) Multinomial Naive Bayes \n",
    "mnb = MultinomialNB()\n",
    "improved_candidates.append(\n",
    "    train_and_eval_model(\n",
    "        \"MultinomialNB (BOW)\",\n",
    "        mnb,\n",
    "        X_train, y_train,\n",
    "        X_dev,   y_dev,\n",
    "        X_test,  y_test,\n",
    "        use_dense=False\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4) LinearSVC \n",
    "linsvm = LinearSVC(C=1.0)\n",
    "improved_candidates.append(\n",
    "    train_and_eval_model(\n",
    "        \"LinearSVC (BOW)\",\n",
    "        linsvm,\n",
    "        X_train, y_train,\n",
    "        X_dev,   y_dev,\n",
    "        X_test,  y_test,\n",
    "        use_dense=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a602d37-8c67-479b-afc5-50dd33e2e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      " BEST IMPROVED MODEL (among 4 candidates)\n",
      " Model:        LogisticRegression (BOW)\n",
      " Dev macro F1: 0.6147\n",
      " Test macro F1: 0.6094\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_candidate = None\n",
    "best_f_macro = -1.0\n",
    "\n",
    "for cand in improved_candidates:\n",
    "    f_macro = cand[\"dev_scores\"][\"f-macro\"]\n",
    "    if f_macro > best_f_macro:\n",
    "        best_f_macro = f_macro\n",
    "        best_candidate = cand\n",
    "\n",
    "print(\"=============================================\")\n",
    "print(\" BEST IMPROVED MODEL (among 4 candidates)\")\n",
    "print(\" Model:       \", best_candidate[\"name\"])\n",
    "print(\" Dev macro F1:\", f\"{best_candidate['dev_scores']['f-macro']:.4f}\")\n",
    "print(\" Test macro F1:\",\n",
    "      f\"{best_candidate['test_scores']['f-macro']:.4f}\")\n",
    "print(\"=============================================\\n\")\n",
    "\n",
    "improved_name = best_candidate[\"name\"]\n",
    "improved_clf = best_candidate[\"clf\"]\n",
    "y_train_pred_improved = best_candidate[\"y_train_pred\"]\n",
    "y_dev_pred_improved   = best_candidate[\"y_dev_pred\"]\n",
    "y_test_pred_improved  = best_candidate[\"y_test_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff7a49a-e8c9-413a-b207-9465043cfeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved classification.csv with rows:\n",
      "baseline train  f-macro=0.9993\n",
      "baseline dev    f-macro=0.5603\n",
      "baseline test   f-macro=0.5583\n",
      "improved train  f-macro=0.9721\n",
      "improved dev    f-macro=0.6147\n",
      "improved test   f-macro=0.6094\n"
     ]
    }
   ],
   "source": [
    "def add_result_row(result_list, system_name, split_name, y_true, y_pred):\n",
    "    scores = compute_scores(y_true, y_pred)\n",
    "    row = {\"system\": system_name, \"split\": split_name}\n",
    "    row.update(scores)\n",
    "    result_list.append(row)\n",
    "\n",
    "results = []\n",
    "\n",
    "# baseline rows\n",
    "add_result_row(results, \"baseline\", \"train\", y_train, y_train_pred_baseline)\n",
    "add_result_row(results, \"baseline\", \"dev\",   y_dev,   y_dev_pred_baseline)\n",
    "add_result_row(results, \"baseline\", \"test\",  y_test,  y_test_pred_baseline)\n",
    "\n",
    "# improved rows (using best candidate)\n",
    "add_result_row(results, \"improved\", \"train\", y_train, y_train_pred_improved)\n",
    "add_result_row(results, \"improved\", \"dev\",   y_dev,   y_dev_pred_improved)\n",
    "add_result_row(results, \"improved\", \"test\",  y_test,  y_test_pred_improved)\n",
    "\n",
    "header = [\n",
    "    \"system\", \"split\",\n",
    "    \"p-pos\", \"r-pos\", \"f-pos\",\n",
    "    \"p-neg\", \"r-neg\", \"f-neg\",\n",
    "    \"p-neu\", \"r-neu\", \"f-neu\",\n",
    "    \"p-macro\", \"r-macro\", \"f-macro\"\n",
    "]\n",
    "\n",
    "with open(\"classification.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    for row in results:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Saved classification.csv with rows:\")\n",
    "for row in results:\n",
    "    print(f\"{row['system']:8s} {row['split']:5s}  f-macro={row['f-macro']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c18ee6-05d6-40f3-9db4-723950d465a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
