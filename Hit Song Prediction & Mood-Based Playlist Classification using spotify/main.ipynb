{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a6d7ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f059c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('label_data.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e97ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9161 entries, 0 to 9160\n",
      "Data columns (total 22 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Rank                              9161 non-null   int64  \n",
      " 1   Title                             9161 non-null   object \n",
      " 2   Artists                           9161 non-null   object \n",
      " 3   Date                              9161 non-null   object \n",
      " 4   Danceability                      9161 non-null   float64\n",
      " 5   Energy                            9161 non-null   float64\n",
      " 6   Loudness                          9161 non-null   float64\n",
      " 7   Speechiness                       9161 non-null   float64\n",
      " 8   Acousticness                      9161 non-null   float64\n",
      " 9   Instrumentalness                  9161 non-null   float64\n",
      " 10  Valence                           9161 non-null   float64\n",
      " 11  # of Artist                       9161 non-null   object \n",
      " 12  Artist (Ind.)                     9161 non-null   object \n",
      " 13  # of Nationality                  9161 non-null   object \n",
      " 14  Nationality                       9161 non-null   object \n",
      " 15  Continent                         9161 non-null   object \n",
      " 16  Points (Total)                    9161 non-null   int64  \n",
      " 17  Points (Ind for each Artist/Nat)  9161 non-null   float64\n",
      " 18  id                                9161 non-null   object \n",
      " 19  Song URL                          9161 non-null   object \n",
      " 20  Loudness_norm                     9161 non-null   float64\n",
      " 21  Popular                           9161 non-null   int64  \n",
      "dtypes: float64(9), int64(3), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9161, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Explore the data\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d748b2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank                                0\n",
       "Title                               0\n",
       "Artists                             0\n",
       "Date                                0\n",
       "Danceability                        0\n",
       "Energy                              0\n",
       "Loudness                            0\n",
       "Speechiness                         0\n",
       "Acousticness                        0\n",
       "Instrumentalness                    0\n",
       "Valence                             0\n",
       "# of Artist                         0\n",
       "Artist (Ind.)                       0\n",
       "# of Nationality                    0\n",
       "Nationality                         0\n",
       "Continent                           0\n",
       "Points (Total)                      0\n",
       "Points (Ind for each Artist/Nat)    0\n",
       "id                                  0\n",
       "Song URL                            0\n",
       "Loudness_norm                       0\n",
       "Popular                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Handle missing values if any\n",
    "# df.dropna(inplace=True)  # or\n",
    "# df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb1485ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rank', 'Title', 'Artists', 'Date', 'Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Valence', '# of Artist', 'Artist (Ind.)', '# of Nationality', 'Nationality', 'Continent', 'Points (Total)', 'Points (Ind for each Artist/Nat)', 'id', 'Song URL', 'Loudness_norm', 'Popular']\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c3e92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Separate features (X) and target (y)\n",
    "# Replace 'target_column' with your actual target column name\n",
    "X = df.drop('Popular', axis=1)\n",
    "y = df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "630d5cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50fa4074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.73813421 0.73799127 0.73799127 0.73853712 0.73853712]\n",
      "Mean CV Score: 0.7382\n",
      "Std CV Score: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross-Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std CV Score: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b778253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank                                  int64\n",
      "Title                                object\n",
      "Artists                              object\n",
      "Date                                 object\n",
      "Danceability                        float64\n",
      "Energy                              float64\n",
      "Loudness                            float64\n",
      "Speechiness                         float64\n",
      "Acousticness                        float64\n",
      "Instrumentalness                    float64\n",
      "Valence                             float64\n",
      "# of Artist                          object\n",
      "Artist (Ind.)                        object\n",
      "# of Nationality                     object\n",
      "Nationality                          object\n",
      "Continent                            object\n",
      "Points (Total)                        int64\n",
      "Points (Ind for each Artist/Nat)    float64\n",
      "id                                   object\n",
      "Song URL                             object\n",
      "Loudness_norm                       float64\n",
      "Popular                               int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "   Rank              Title                     Artists        Date  \\\n",
      "0     1    Ella Baila Sola  Eslabon Armado, Peso Pluma  2023-05-29   \n",
      "1     2     WHERE SHE GOES                   Bad Bunny  2023-05-29   \n",
      "2     3    La Bebe - Remix       Yng Lvcas, Peso Pluma  2023-05-29   \n",
      "3     4  Cupid - Twin Ver.                 FIFTY FIFTY  2023-05-29   \n",
      "4     5          un x100to   Grupo Frontera, Bad Bunny  2023-05-29   \n",
      "\n",
      "   Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
      "0         0.668   0.758    -5.176        0.033         0.483   \n",
      "1         0.652   0.800    -4.019        0.061         0.143   \n",
      "2         0.812   0.479    -5.678        0.333         0.213   \n",
      "3         0.783   0.592    -8.332        0.033         0.435   \n",
      "4         0.569   0.724    -4.076        0.047         0.228   \n",
      "\n",
      "   Instrumentalness  ...   Artist (Ind.) # of Nationality  Nationality  \\\n",
      "0             0.000  ...  Eslabon Armado    Nationality 1       Mexico   \n",
      "1             0.629  ...       Bad Bunny    Nationality 1  Puerto Rico   \n",
      "2             0.000  ...       Yng Lvcas    Nationality 1       Mexico   \n",
      "3             0.000  ...     FIFTY FIFTY    Nationality 1  South Korea   \n",
      "4             0.000  ...  Grupo Frontera    Nationality 1       Mexico   \n",
      "\n",
      "       Continent Points (Total) Points (Ind for each Artist/Nat)  \\\n",
      "0  Latin-America            200                            100.0   \n",
      "1  Latin-America            199                            199.0   \n",
      "2  Latin-America            198                             99.0   \n",
      "3           Asia            197                            197.0   \n",
      "4  Latin-America            196                             98.0   \n",
      "\n",
      "                       id                                           Song URL  \\\n",
      "0  3qQbCzHBycnDpGskqOWY0E  https://open.spotify.com/track/3qQbCzHBycnDpGs...   \n",
      "1  7ro0hRteUMfnOioTFI5TG1  https://open.spotify.com/track/7ro0hRteUMfnOio...   \n",
      "2  2UW7JaomAMuX9pZrjVpHAU  https://open.spotify.com/track/2UW7JaomAMuX9pZ...   \n",
      "3  7FbrGaHYVDmfr7KoLIZnQ7  https://open.spotify.com/track/7FbrGaHYVDmfr7K...   \n",
      "4  6pD0ufEQq0xdHSsRbg9LBK  https://open.spotify.com/track/6pD0ufEQq0xdHSs...   \n",
      "\n",
      "  Loudness_norm Popular  \n",
      "0      0.849862       1  \n",
      "1      0.883423       1  \n",
      "2      0.835301       1  \n",
      "3      0.758318       1  \n",
      "4      0.881769       1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check data types of all columns\n",
    "print(df.dtypes)\n",
    "print(\"\\n\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6601036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['Rank', 'Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Valence', 'Points (Total)', 'Points (Ind for each Artist/Nat)', 'Loudness_norm', 'Popular']\n"
     ]
    }
   ],
   "source": [
    "# Identify and handle categorical columns\n",
    "# Option 1: Drop non-numeric columns (like song names, artist names)\n",
    "# These are usually identifiers and don't help with prediction\n",
    "\n",
    "# Get only numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "# Remove target from numeric columns if present\n",
    "if 'Popular' in numeric_cols:\n",
    "    numeric_cols.remove('Popular')\n",
    "\n",
    "X = df[numeric_cols]\n",
    "y = df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fcb580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['Rank', 'Title', 'Artists', 'Date', 'Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Valence', '# of Artist', 'Artist (Ind.)', '# of Nationality', 'Nationality', 'Continent', 'Points (Total)', 'Points (Ind for each Artist/Nat)', 'id', 'Song URL', 'Loudness_norm', 'Popular']\n",
      "\n",
      "Requested features: ['Danceability', 'Energy', 'Loudness_norm', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Valence']\n",
      "\n",
      "All requested features are available!\n",
      "\n",
      "X shape: (9161, 7)\n",
      "y shape: (9161,)\n"
     ]
    }
   ],
   "source": [
    "# Select specific features\n",
    "feature_cols = ['Danceability', 'Energy', 'Loudness_norm', 'Speechiness', \n",
    "                'Acousticness', 'Instrumentalness', 'Valence']\n",
    "\n",
    "# Check if all features exist in the dataframe\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "print(\"\\nRequested features:\", feature_cols)\n",
    "\n",
    "# Verify which features are present\n",
    "missing_cols = [col for col in feature_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"\\nWarning: These columns are missing: {missing_cols}\")\n",
    "else:\n",
    "    print(\"\\nAll requested features are available!\")\n",
    "\n",
    "# Create X with only the selected features\n",
    "X = df[feature_cols]\n",
    "y = df['Popular']\n",
    "\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "994ffa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.73813421 0.73799127 0.73799127 0.73853712 0.73853712]\n",
      "Mean CV Score: 0.7382\n",
      "Std CV Score: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Now proceed with K-Fold Cross-Validation using selected features\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std CV Score: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "054e15b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7352\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85      2021\n",
      "           1       0.00      0.00      0.00       728\n",
      "\n",
      "    accuracy                           0.74      2749\n",
      "   macro avg       0.37      0.50      0.42      2749\n",
      "weighted avg       0.54      0.74      0.62      2749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/AmlSpotify/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/AmlSpotify/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/miniconda3/envs/AmlSpotify/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Then train final model on full training set and evaluate on test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(f\"\\nTest Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d324e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Popular\n",
      "0    6763\n",
      "1    2398\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class proportions:\n",
      "Popular\n",
      "0    0.738238\n",
      "1    0.261762\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Check class distribution\n",
    "print(\"Class distribution:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nClass proportions:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "946405b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.5504\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.55      0.64      1686\n",
      "           1       0.30      0.55      0.39       605\n",
      "\n",
      "    accuracy                           0.55      2291\n",
      "   macro avg       0.54      0.55      0.52      2291\n",
      "weighted avg       0.65      0.55      0.58      2291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Handle class imbalance - Use class_weight parameter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Automatically balance classes\n",
    "model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40f61377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Test Accuracy: 0.7460\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85      1686\n",
      "           1       0.57      0.16      0.25       605\n",
      "\n",
      "    accuracy                           0.75      2291\n",
      "   macro avg       0.66      0.56      0.55      2291\n",
      "weighted avg       0.71      0.75      0.69      2291\n",
      "\n",
      "[[1611   75]\n",
      " [ 507   98]]\n"
     ]
    }
   ],
   "source": [
    "# 4. Try different models that handle imbalance better\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random Forest with balanced class weights\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred_rf)}\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1eda0024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With threshold 0.3:\n",
      "Test Accuracy: 0.2649\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1686\n",
      "           1       0.26      1.00      0.42       605\n",
      "\n",
      "    accuracy                           0.26      2291\n",
      "   macro avg       0.63      0.50      0.21      2291\n",
      "weighted avg       0.81      0.26      0.11      2291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Adjust decision threshold\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get probability predictions\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Try different threshold (default is 0.5)\n",
    "threshold = 0.3  # Lower threshold to predict more class 1\n",
    "y_pred_adjusted = (y_proba >= threshold).astype(int)\n",
    "\n",
    "print(f\"\\nWith threshold {threshold}:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_adjusted):.4f}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred_adjusted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a5af3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.1-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/AmlSpotify/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/AmlSpotify/lib/python3.11/site-packages (from xgboost) (1.16.2)\n",
      "Downloading xgboost-3.1.1-py3-none-macosx_12_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.1\n",
      "Class ratio (class 0 / class 1): 2.83\n",
      "\n",
      "XGBoost Results:\n",
      "Test Accuracy: 0.6032\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71      1686\n",
      "           1       0.33      0.48      0.39       605\n",
      "\n",
      "    accuracy                           0.60      2291\n",
      "   macro avg       0.55      0.57      0.55      2291\n",
      "weighted avg       0.66      0.60      0.62      2291\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1089  597]\n",
      " [ 312  293]]\n"
     ]
    }
   ],
   "source": [
    "# Try XGBoost with scale_pos_weight\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Calculate the ratio for class imbalance\n",
    "class_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Class ratio (class 0 / class 1): {class_ratio:.2f}\")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=class_ratio,  # Handle class imbalance\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred_xgb)}\")\n",
    "print(f\"\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred_xgb)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmlSpotify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
